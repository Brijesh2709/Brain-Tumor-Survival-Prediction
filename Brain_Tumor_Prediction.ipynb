{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Brain Tumor Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "w_mQa5W4oQHF",
        "ibS6a8vbkU2b",
        "zazyjmoDxZ_d",
        "9NiJJmKGWn_c"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpD4JlCHWn-8"
      },
      "source": [
        "# Brain Tumor Patient Survival Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNytq7t60DAX"
      },
      "source": [
        "#### Challenge is to develop a model to predict brain tumor patient survival. The goal is both to create a high-performing algorithm for the target task, as well as to analyze performance across several different architecture permutations. Three different network designs are designed. Each model is built and trained, and the final of each  model is saved as `*.hdf5` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O7w9CdkWn_K"
      },
      "source": [
        "### Jarvis library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2z9c4xZWn_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "150a5f33-5dca-4a7f-cba7-17711f27b25a"
      },
      "source": [
        "% pip install jarvis-md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/8c/c0e9a5cc4840e50d0743824996f84a95922c4e21a71a991572323328df9e/jarvis_md-0.0.1a14-py3-none-any.whl (81kB)\n",
            "\r\u001b[K     |████                            | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.19.5)\n",
            "Collecting pyyaml>=5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.1.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->jarvis-md) (1.15.0)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a14 pyyaml-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xKSGgRfWn_O"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va3Xqpn-Wn_Q"
      },
      "source": [
        "import os, numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "from jarvis.train import datasets, custom"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdYWhUBrWn_R"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkvRr7gt0c4J"
      },
      "source": [
        "The data used here will consist of brain tumor MRI exams derived from the MICCAI Brain Tumor Segmentation Challenge (BRaTS)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fioKFXTMWn_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a55566-1e02-4696-af67-9c0a01f2729d"
      },
      "source": [
        "datasets.download(name='mr/brats-2020-096')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 20:08:27 ] [====================] 100.000% : Extracting archive (0000486 / 0000486) "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': '/data/raw/mr_brats_2020', 'data': '/data/raw/mr_brats_2020'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PmpuzXJWn_U"
      },
      "source": [
        "### Python generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc4N-Jj-Yem5"
      },
      "source": [
        "configs = {'specs': {'ys': {\n",
        "    'tumor': {\n",
        "        'dtype': 'uint8',\n",
        "        'loads': 'lbl-crp',\n",
        "        'norms': {'clip': {'min': 0, 'max': 1}},\n",
        "        'shape': [96, 96, 96, 1]},\n",
        "    'survival': {\n",
        "        'dtype': 'float32',\n",
        "        'loads': 'survival_days_norm',\n",
        "        'shape': [1]}}}}\n",
        "\n",
        "gen_train, gen_valid, client = datasets.prepare(\n",
        "    name='mr/brats-2020-096', \n",
        "    keyword='096*vox-org',\n",
        "    configs=configs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZL7Shr_O0jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d85712-5bc4-4621-d577-324f04a4ee58"
      },
      "source": [
        "xs, ys = next(gen_train)\n",
        "\n",
        "print('xs keys: {}'.format(xs.keys()))\n",
        "print('ys keys: {}'.format(ys.keys()))\n",
        "\n",
        "print('xs shape: {}'.format(xs['dat'].shape))\n",
        "print('ys shape: {}'.format(ys['tumor'].shape))\n",
        "print('ys shape: {}'.format(ys['survival'].shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xs keys: dict_keys(['dat'])\n",
            "ys keys: dict_keys(['tumor', 'survival'])\n",
            "xs shape: (3, 96, 96, 96, 4)\n",
            "ys shape: (3, 96, 96, 96, 1)\n",
            "ys shape: (3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoE4ETBSWn_V"
      },
      "source": [
        "### Model inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgixFjEeWn_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3648dc-1c52-4264-824e-765f96e0794e"
      },
      "source": [
        "inputs = client.get_inputs(Input)\n",
        "\n",
        "print(inputs)\n",
        "print(inputs.keys())\n",
        "print(inputs['dat'].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dat': <KerasTensor: shape=(None, 96, 96, 96, 4) dtype=float32 (created by layer 'dat')>}\n",
            "dict_keys(['dat'])\n",
            "(None, 96, 96, 96, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7omusWbWn_X"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_mQa5W4oQHF"
      },
      "source": [
        "### Model 1 - Fully Convolutional Network using Contracting and Expanding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfUF37KDWn_Y"
      },
      "source": [
        "kwargs = {\n",
        "    'kernel_size': (3, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=2)))\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=2)))\n",
        "\n",
        "l1 = conv1(8, inputs['dat'])\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "l6  = tran2(48, l5)\n",
        "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
        "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
        "l9  = tran2(8,  conv1(16, concat(l2, l8)))\n",
        "l10 = conv1(8,  l9)\n",
        "\n",
        "logits = {}\n",
        "logits['survival'] = layers.Conv3D(filters=1, name='survival', activation='sigmoid', **kwargs)(l10)\n",
        "logits['tumor'] = layers.Conv3D(filters=2, name='tumor', **kwargs)(l10)\n",
        "model1 = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IZqLMxXJaXY"
      },
      "source": [
        "model1.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={\n",
        "        'survival': losses.MeanSquaredError(),\n",
        "        'tumor': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrKyEEQcRnSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bffa7a2a-e4ee-4e88-b7c9-3520152dfd24"
      },
      "source": [
        "client.load_data_in_memory()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 15:03:04 ] [====================] 100.000% : Iterating | 000235    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZhNQAhBXmfK"
      },
      "source": [
        "def generator(G):\n",
        "    for xs, ys in G:\n",
        " \n",
        "        survival = ys['survival'].reshape(-1, 1, 1, 1, 1)\n",
        " \n",
        "        ys['survival'] = np.zeros((survival.shape[0], 96, 96, 96, 1), dtype='float32')\n",
        "        ys['survival'][:] = survival\n",
        " \n",
        "        yield xs, ys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIBFFL4rRx2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d472463a-9bc8-4901-f737-3a302f110933"
      },
      "source": [
        "model1.fit(\n",
        "    x=generator(gen_train), \n",
        "    steps_per_epoch=125, \n",
        "    epochs=4,\n",
        "    validation_data=generator(gen_valid),\n",
        "    validation_steps=125,\n",
        "    validation_freq=2,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "125/125 [==============================] - 205s 1s/step - loss: 0.3026 - survival_loss: 0.0321 - tumor_loss: 0.2706\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 207s 2s/step - loss: 0.1310 - survival_loss: 0.0117 - tumor_loss: 0.1193 - val_loss: 0.1336 - val_survival_loss: 0.0079 - val_tumor_loss: 0.1257\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 165s 1s/step - loss: 0.1105 - survival_loss: 0.0111 - tumor_loss: 0.0994\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 206s 2s/step - loss: 0.0981 - survival_loss: 0.0110 - tumor_loss: 0.0871 - val_loss: 0.1096 - val_survival_loss: 0.0070 - val_tumor_loss: 0.1026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc99065b6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R899xTW1aPzY"
      },
      "source": [
        "test_train, test_valid = client.create_generators(test=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXO0wZx0JERk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70a5736-a0d9-4668-e5df-035cea0a8d2c"
      },
      "source": [
        "preds_train = []\n",
        "trues_train = []\n",
        "mae_train = []\n",
        "\n",
        "for x, y in test_train:\n",
        "    \n",
        "    logits = model1.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    preds_train.append(logits.ravel())\n",
        "    trues_train.append(y['survival'].ravel())\n",
        "    mae_train.append(np.abs(preds_train[-1] - trues_train[-1]))\n",
        "\n",
        "mae_train = np.array(mae_train).ravel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 15:17:24 ] [====================] 100.000% : Iterating | 000185    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z087QE-SJMR6"
      },
      "source": [
        "df1_train = pd.DataFrame(index=np.arange(mae_train.size))\n",
        "df1_train['MAE'] = mae_train\n",
        "\n",
        "df1_train_mean = df1_train['MAE'].mean()\n",
        "df1_train_median = df1_train['MAE'].median()\n",
        "df1_train_25per = df1_train['MAE'].quantile(0.25)\n",
        "df1_train_75per = df1_train['MAE'].quantile(0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IvQBVmOJOrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e69cbab-e3af-402d-9b68-33fca21c35a8"
      },
      "source": [
        "preds_valid = []\n",
        "trues_valid = []\n",
        "mae_valid = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    logits = model1.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    preds_valid.append(logits.ravel())\n",
        "    trues_valid.append(y['survival'].ravel())\n",
        "    mae_valid.append(np.abs(preds_valid[-1] - trues_valid[-1]))\n",
        "\n",
        "mae_valid = np.array(mae_valid).ravel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 15:18:00 ] [====================] 100.000% : Iterating | 000050    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmrWYFemJQ3X"
      },
      "source": [
        "df1_valid = pd.DataFrame(index=np.arange(mae_valid.size))\n",
        "df1_valid['MAE'] = mae_valid\n",
        "\n",
        "df1_valid_mean = df1_valid['MAE'].mean()\n",
        "df1_valid_median = df1_valid['MAE'].median()\n",
        "df1_valid_25per = df1_valid['MAE'].quantile(0.25)\n",
        "df1_valid_75per = df1_valid['MAE'].quantile(0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXoCSpoWJUUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2190e78-9aa7-4ef0-be99-a0701603db0d"
      },
      "source": [
        "print(df1_train_median)\n",
        "print(df1_valid_median)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06330692768096924\n",
            "0.0630541443824768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAXHnTHB7R8A"
      },
      "source": [
        "model1.save('./Model1.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibS6a8vbkU2b"
      },
      "source": [
        "### Model 2 - Global regression type loss function using Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6r2q4DEkXZA"
      },
      "source": [
        "kwargs = {\n",
        "    'kernel_size': (3, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=2)))\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=2)))\n",
        "\n",
        "l1 = conv1(16, inputs['dat'])\n",
        "l2 = conv1(24, conv2(24, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "l6  = tran2(48, l5)\n",
        "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
        "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
        "l9  = tran2(8,  conv1(16, concat(l2, l8)))\n",
        "l10 = conv1(8,  l9)\n",
        "\n",
        "logits = {}\n",
        "logits['survival'] = layers.Dense(1, activation='sigmoid', name='survival')(l10)\n",
        "logits['tumor'] = layers.Dense(1, activation='sigmoid', name='tumor')(l10)\n",
        "model2 = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFtt1WukmIx2"
      },
      "source": [
        "model2.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={\n",
        "        'survival': losses.MeanSquaredError(),\n",
        "        'tumor': losses.MeanSquaredError()},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfIjpTtQtDGz"
      },
      "source": [
        "def generator(G):\n",
        "    for xs, ys in G:\n",
        " \n",
        "        survival = ys['survival'].reshape(-1, 1, 1, 1, 1)\n",
        " \n",
        "        ys['survival'] = np.zeros((survival.shape[0], 96, 96, 96, 1), dtype='float32')\n",
        "        ys['survival'][:] = survival\n",
        " \n",
        "        yield xs, ys"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5mw6WwJmTpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d996f3-1aec-4067-89e8-de94d40bb586"
      },
      "source": [
        "model2.fit(\n",
        "    x=generator(gen_train), \n",
        "    steps_per_epoch=125, \n",
        "    epochs=4,\n",
        "    validation_data=generator(gen_valid),\n",
        "    validation_steps=125,\n",
        "    validation_freq=2,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "125/125 [==============================] - 100s 499ms/step - loss: 0.1443 - survival_loss: 0.0281 - tumor_loss: 0.1162\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 146s 1s/step - loss: 0.1008 - survival_loss: 0.0199 - tumor_loss: 0.0810 - val_loss: 0.0931 - val_survival_loss: 0.0154 - val_tumor_loss: 0.0777\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 64s 508ms/step - loss: 0.0845 - survival_loss: 0.0164 - tumor_loss: 0.0681\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 117s 936ms/step - loss: 0.0742 - survival_loss: 0.0153 - tumor_loss: 0.0589 - val_loss: 0.0713 - val_survival_loss: 0.0152 - val_tumor_loss: 0.0561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4eeb35c050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptqiwC7zvVpp"
      },
      "source": [
        "test_train, test_valid = client.create_generators(test=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNY82i4mmYGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac2dc2c-5bed-49fc-948e-0e0fc8758943"
      },
      "source": [
        "preds_train = []\n",
        "trues_train = []\n",
        "mae_train = []\n",
        "\n",
        "for x, y in test_train:\n",
        "    \n",
        "    logits = model2.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    preds_train.append(logits.ravel())\n",
        "    trues_train.append(y['survival'].ravel())\n",
        "    mae_train.append(np.abs(preds_train[-1] - trues_train[-1]))\n",
        "\n",
        "mae_train = np.array(mae_train).ravel()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 20:17:00 ] [====================] 100.000% : Iterating | 000185    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk-CEKzymcMC"
      },
      "source": [
        "df2_train = pd.DataFrame(index=np.arange(mae_train.size))\n",
        "df2_train['MAE'] = mae_train\n",
        "\n",
        "df2_train_mean = df2_train['MAE'].mean()\n",
        "df2_train_median = df2_train['MAE'].median()\n",
        "df2_train_25per = df2_train['MAE'].quantile(0.25)\n",
        "df2_train_75per = df2_train['MAE'].quantile(0.75)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8r3wX7-mewg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4ea4a1-eccc-4d03-e145-d7a939ef3821"
      },
      "source": [
        "preds_valid = []\n",
        "trues_valid = []\n",
        "mae_valid = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    logits = model2.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    preds_valid.append(logits.ravel())\n",
        "    trues_valid.append(y['survival'].ravel())\n",
        "    mae_valid.append(np.abs(preds_valid[-1] - trues_valid[-1]))\n",
        "\n",
        "mae_valid = np.array(mae_valid).ravel()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 20:17:31 ] [====================] 100.000% : Iterating | 000050    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05CuL_0pmkq1"
      },
      "source": [
        "df2_valid = pd.DataFrame(index=np.arange(mae_valid.size))\n",
        "df2_valid['MAE'] = mae_valid\n",
        "\n",
        "df2_valid_mean = df2_valid['MAE'].mean()\n",
        "df2_valid_median = df2_valid['MAE'].median()\n",
        "df2_valid_25per = df2_valid['MAE'].quantile(0.25)\n",
        "df2_valid_75per = df2_valid['MAE'].quantile(0.75)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ppjdHht7APT"
      },
      "source": [
        "Data = {\"\": [\"model2\"],\n",
        "        \"Mean Train\":[df2_train_mean],\n",
        "        \"Median Train\": [df2_train_median],\n",
        "        \"25th Tile Train\": [df2_train_25per],\n",
        "        \"75th Tile Train\": [df2_train_75per],\n",
        "        \"Mean Valid\":[df2_valid_mean],\n",
        "        \"Median Valid\": [df2_valid_median],\n",
        "        \"25th Tile Valid\": [df2_valid_25per],\n",
        "        \"75th Tile Valid\": [df2_valid_75per]}\n",
        "\n",
        "df = pd.DataFrame(Data)           \n",
        "fname = './bmuthuma_results2.csv'\n",
        "df.to_csv(fname)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OXqhw6f7u8P"
      },
      "source": [
        "model2.save('./Model2.hdf5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zazyjmoDxZ_d"
      },
      "source": [
        "### Model 3 - Pretrained Auto Encoder Strategy using SE Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7C4HfwmxlHx"
      },
      "source": [
        "kwargs = {\n",
        "    'kernel_size': (3, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=2)))\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=2)))\n",
        "\n",
        "l1 = conv1(8, inputs['dat'])\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "p1 = layers.GlobalAveragePooling3D()(l5)\n",
        "\n",
        "ch = int(p1.shape[-1] / 4)\n",
        "f1 = layers.Dense(ch, activation='relu')(p1)\n",
        "\n",
        "scale = layers.Dense(l5.shape[-1], activation='sigmoid')(f1)\n",
        "scale = layers.Reshape((1, 1, 1, l5.shape[-1]))(scale)    \n",
        "\n",
        "l5 = l5 * scale\n",
        "\n",
        "n0, n1, c = l5.shape[-3:]\n",
        "f0 = layers.Reshape([-1, 1, 1, n0 * n1 * c])(l5)\n",
        "\n",
        "l6 = tran2(48, l5)\n",
        "\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "concat(l4, l6)\n",
        "\n",
        "l7 = tran2(32, conv1(48, l6 + conv1(48, l4)))\n",
        "l8 = tran2(16, conv1(32, l7 + conv1(32, l3)))\n",
        "l9 = tran2(8,  conv1(16, l8 + conv1(16, l2)))\n",
        "l10 = conv1(8,  l9)\n",
        "\n",
        "encoder = Model(inputs=inputs, outputs=l10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Yhv4tn3rEM"
      },
      "source": [
        "encoder.trainable = False\n",
        "latent = encoder(inputs)\n",
        "h0 = layers.Flatten()(latent)\n",
        "h1 = layers.Dense(32, activation='relu')(h0)\n",
        "\n",
        "logits = {}\n",
        "logits['survival'] = layers.Dense(1, activation='sigmoid', name='survival')(latent)\n",
        "logits['tumor'] = layers.Dense(1, activation='sigmoid', name='tumor')(latent)\n",
        "model3 = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnbTBZ6Dmvgm"
      },
      "source": [
        "model3.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={\n",
        "        'survival': losses.MeanSquaredError(),\n",
        "        'tumor': losses.MeanSquaredError()},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw09CSsiytNY"
      },
      "source": [
        "def generator(G):\n",
        "    for xs, ys in G:\n",
        " \n",
        "        survival = ys['survival'].reshape(-1, 1, 1, 1, 1)\n",
        " \n",
        "        ys['survival'] = np.zeros((survival.shape[0], 96, 96, 96, 1), dtype='float32')\n",
        "        ys['survival'][:] = survival\n",
        " \n",
        "        yield xs, ys"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn1oyZ9Cy6TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbfd34b-0e67-439a-d3b2-2533609cd1a9"
      },
      "source": [
        "model3.fit(\n",
        "    x=generator(gen_train), \n",
        "    steps_per_epoch=125, \n",
        "    epochs=4,\n",
        "    validation_data=generator(gen_valid),\n",
        "    validation_steps=125,\n",
        "    validation_freq=2,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "125/125 [==============================] - 88s 409ms/step - loss: 0.2565 - survival_loss: 0.0151 - tumor_loss: 0.2414\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 135s 1s/step - loss: 0.2514 - survival_loss: 0.0139 - tumor_loss: 0.2375 - val_loss: 0.2509 - val_survival_loss: 0.0141 - val_tumor_loss: 0.2368\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 47s 379ms/step - loss: 0.2478 - survival_loss: 0.0138 - tumor_loss: 0.2340\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 104s 834ms/step - loss: 0.2435 - survival_loss: 0.0128 - tumor_loss: 0.2307 - val_loss: 0.2426 - val_survival_loss: 0.0122 - val_tumor_loss: 0.2305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb9e0b10e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkCYvOid5RaU"
      },
      "source": [
        "test_train, test_valid = client.create_generators(test=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgLfcCigm722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd7a82b-180e-4192-9395-e46285fbeac2"
      },
      "source": [
        "preds_train = []\n",
        "trues_train = []\n",
        "mae_train = []\n",
        "\n",
        "for x, y in test_train:\n",
        "    \n",
        "    logits = model3.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    preds_train.append(logits.ravel())\n",
        "    trues_train.append(y['survival'].ravel())\n",
        "    mae_train.append(np.abs(preds_train[-1] - trues_train[-1]))\n",
        "\n",
        "mae_train = np.array(mae_train).ravel()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 20:03:59 ] [====================] 100.000% : Iterating | 000185    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQIWDDNZm_wb"
      },
      "source": [
        "df3_train = pd.DataFrame(index=np.arange(mae_train.size))\n",
        "df3_train['MAE'] = mae_train\n",
        "\n",
        "df3_train_mean = df3_train['MAE'].mean()\n",
        "df3_train_median = df3_train['MAE'].median()\n",
        "df3_train_25per = df3_train['MAE'].quantile(0.25)\n",
        "df3_train_75per = df3_train['MAE'].quantile(0.75)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnO8TLehnCIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e639f068-0416-43f8-ec85-5fa7e986a5b3"
      },
      "source": [
        "preds_valid = []\n",
        "trues_valid = []\n",
        "mae_valid = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    logits = model3.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    preds_valid.append(logits.ravel())\n",
        "    trues_valid.append(y['survival'].ravel())\n",
        "    mae_valid.append(np.abs(preds_valid[-1] - trues_valid[-1]))\n",
        "\n",
        "mae_valid = np.array(mae_valid).ravel()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-06 20:04:45 ] [====================] 100.000% : Iterating | 000050    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT0_aLeanIfQ"
      },
      "source": [
        "df3_valid = pd.DataFrame(index=np.arange(mae_valid.size))\n",
        "df3_valid['MAE'] = mae_valid\n",
        "\n",
        "df3_valid_mean = df3_valid['MAE'].mean()\n",
        "df3_valid_median = df3_valid['MAE'].median()\n",
        "df3_valid_25per = df3_valid['MAE'].quantile(0.25)\n",
        "df3_valid_75per = df3_valid['MAE'].quantile(0.75)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAFk0_oh75ov"
      },
      "source": [
        "model3.save('./Model3.hdf5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NxvY-3mWn_Z"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "For each of the three models, the following metrics is calculated for **both the training and validation** cohorts:\n",
        "\n",
        "* absolute error, mean\n",
        "* absolute error, median\n",
        "* absolute error, 25th percentile\n",
        "* absolute error, 75th percentile "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO2K9QrHWn_b"
      },
      "source": [
        "Data = {\"\": [\"model1\", \"model2\", \"model3\"],\n",
        "        \"Mean Train\":[df1_train_mean, df2_train_mean, df3_train_mean],\n",
        "        \"Median Train\": [df1_train_median, df2_train_median, df3_train_median],\n",
        "        \"25th Tile Train\": [df1_train_25per, df2_train_25per, df3_train_25per],\n",
        "        \"75th Tile Train\": [df1_train_75per, df2_train_75per, df3_train_75per],\n",
        "        \"Mean Valid\":[df1_valid_mean, df2_valid_mean, df3_valid_mean],\n",
        "        \"Median Valid\": [df1_valid_median, df2_valid_median, df3_valid_median],\n",
        "        \"25th Tile Valid\": [df1_valid_25per, df2_valid_25per, df3_valid_25per],\n",
        "        \"75th Tile Valid\": [df1_valid_75per, df2_valid_75per, df3_valid_75per]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NiJJmKGWn_c"
      },
      "source": [
        "### Results\n",
        "\n",
        "Stored **training and validation** cohort statistics for the different models in a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaG7MLHoWn_d"
      },
      "source": [
        "df = pd.DataFrame(Data)           \n",
        "fname = './Results.csv'\n",
        "df.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}